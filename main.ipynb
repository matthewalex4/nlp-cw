{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e77a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch) (2026.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2026.2.19)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.13/site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->transformers) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->transformers) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.13/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (9.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from datasets) (3.24.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from datasets) (2.4.2)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-23.0.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets) (3.0.0)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.13/site-packages (from datasets) (4.67.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./.venv/lib/python3.13/site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from datasets) (6.0.3)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.1.2)\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl (490 kB)\n",
      "Downloading multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading pyarrow-23.0.1-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, urllib3, pyarrow, propcache, multidict, fsspec, frozenlist, dill, charset_normalizer, attrs, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspecm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2026.2.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2026.2.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2026.2.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [datasets]/17\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 attrs-25.4.0 charset_normalizer-3.4.4 datasets-4.5.0 dill-0.4.0 frozenlist-1.8.0 fsspec-2025.10.0 multidict-6.7.1 multiprocess-0.70.18 propcache-0.4.1 pyarrow-23.0.1 requests-2.32.5 urllib3-2.6.3 xxhash-3.6.0 yarl-1.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install transformers\n",
    "%pip install ipywidgets\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c39609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.width',1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21dda637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "K = 5\n",
    "\n",
    "LR = 2e-5\n",
    "EPOCHS = 3\n",
    "BSZ = 16\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  par_id                                               text  label_y\n",
      "0   4341  The scheme saw an estimated 150,000 children f...        1\n",
      "1   4136  Durban 's homeless communities reconciliation ...        1\n",
      "2  10352  The next immediate problem that cropped up was...        1\n",
      "3   8279  Far more important than the implications for t...        1\n",
      "4   1164  To strengthen child-sensitive social protectio...        1\n",
      "\n",
      "  par_id                                               text  label_y\n",
      "0   4046  We also know that they can benefit by receivin...        1\n",
      "1   1279  Pope Francis washed and kissed the feet of Mus...        1\n",
      "2   8330  Many refugees do n't want to be resettled anyw...        1\n",
      "3   4063  \"Budding chefs , like \"\" Fred \"\" , \"\" Winston ...        1\n",
      "4   4089  \"In a 90-degree view of his constituency , one...        1\n"
     ]
    }
   ],
   "source": [
    "from dont_patronize_me import DontPatronizeMe\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "dpm = DontPatronizeMe(DATA_PATH, DATA_PATH)\n",
    "dpm.load_task1()\n",
    "\n",
    "data = dpm.train_task1_df\n",
    "\n",
    "trids = pd.read_csv(f'{DATA_PATH}train_semeval_parids-labels.csv')\n",
    "teids = pd.read_csv(f'{DATA_PATH}dev_semeval_parids-labels.csv')\n",
    "\n",
    "trids['par_id'] = trids.par_id.astype(str)\n",
    "teids['par_id'] = teids.par_id.astype(str)\n",
    "\n",
    "cols = ['par_id', 'text', 'label_y']\n",
    "\n",
    "trdf = trids.merge(data, on='par_id', how='left')[cols]\n",
    "tedf = teids.merge(data, on='par_id', how='left')[cols]\n",
    "\n",
    "print(trdf.head())\n",
    "print()\n",
    "print(tedf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58285fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "label_y\n",
      "0    7581\n",
      "1     794\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset({\n",
      "    features: ['par_id', 'text', 'label_y'],\n",
      "    num_rows: 8375\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "counts = trdf['label_y'].value_counts()\n",
    "print(\"Original class distribution:\")\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "weights = torch.tensor([1.0 / counts[0], 1.0 / counts[1]]).to(device)\n",
    "\n",
    "trds = Dataset.from_pandas(trdf)\n",
    "print(trds)\n",
    "\n",
    "# # Upsample positive class\n",
    "# pos_df = trdf[trdf['label_y'] == 1]\n",
    "# neg_df = trdf[trdf['label_y'] == 0]\n",
    "\n",
    "# upsampled_pos_df = pos_df.sample(n=len(neg_df), replace=True, random_state=RANDOM_SEED)\n",
    "# trdf_balanced = pd.concat([neg_df, upsampled_pos_df]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# print(\"\\nBalanced class distribution:\")\n",
    "# print(trdf_balanced['label_y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dc2ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "X = trdf[\"text\"].values\n",
    "y = trdf[\"label_y\"].values\n",
    "\n",
    "folds = list(skf.split(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7b52708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs):\n",
    "        labels = inputs.pop(\"label_y\").view(-1)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.view(-1, self.model.config.num_labels)\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "        return loss_fn(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea8b4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "rob_checkpoint = \"FacebookAI/roberta-base\"\n",
    "deb_checkpoint = \"microsoft/deberta-base\"\n",
    "\n",
    "rob_tokenizer = AutoTokenizer.from_pretrained(rob_checkpoint)\n",
    "deb_tokenizer = AutoTokenizer.from_pretrained(deb_checkpoint)\n",
    "\n",
    "def tokenize(tokenizer, batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "architectures = [(\"Roberta\", rob_checkpoint, rob_tokenizer), (\"Deberta\", deb_checkpoint, deb_tokenizer)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRS = [2e-5, 3e-5, 5e-5]\n",
    "BSZS = [16, 32]\n",
    "\n",
    "# Determine best hyperparameters using k-fold cross-validation\n",
    "def hyperparameter_search():\n",
    "    results = {}\n",
    "    results[\"Roberta\"] = defaultdict(float)\n",
    "    results[\"Deberta\"] = defaultdict(float)\n",
    "\n",
    "    for name, checkpoint, tokenizer in architectures:\n",
    "        print(f\"Training {name}...\")\n",
    "        print()\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "            print(f\"Fold {fold + 1}/{K}\")\n",
    "\n",
    "            trds = Dataset.from_pandas(trdf.iloc[train_idx])\n",
    "            valds = Dataset.from_pandas(trdf.iloc[val_idx])\n",
    "\n",
    "            trds = trds.map(lambda batch: tokenize(tokenizer, batch), batched=True)\n",
    "            valds = valds.map(lambda batch: tokenize(tokenizer, batch), batched=True)\n",
    "\n",
    "            trds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_y\"])\n",
    "            valds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_y\"])\n",
    "\n",
    "            for lr, bsz in product(LRS, BSZS):\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n",
    "                training_args = TrainingArguments(\n",
    "                    output_dir=f'./results/fold_{fold+1}/{name}_lr{lr}_bsz{bsz}',\n",
    "                    learning_rate=lr,\n",
    "                    per_device_train_batch_size=bsz,\n",
    "                    per_device_eval_batch_size=bsz,\n",
    "                    num_train_epochs=EPOCHS,\n",
    "                    logging_dir=f'./logs/fold_{fold+1}/{name}_lr{lr}_bsz{bsz}',\n",
    "                    save_strategy=\"epoch\"\n",
    "                )\n",
    "\n",
    "                trainer = BalancedTrainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=trds,\n",
    "                    eval_dataset=valds\n",
    "                )\n",
    "\n",
    "                trainer.train()\n",
    "                metrics = trainer.evaluate()\n",
    "\n",
    "                results[name][(lr, bsz)] += metrics[\"eval_f1\"]\n",
    "\n",
    "    best_hyperparams = {\n",
    "        name: max(results[name], key=results[name].get)\n",
    "        for name in results\n",
    "    }\n",
    "\n",
    "    return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b40283e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best models on full training set\n",
    "def train_models(best_hyperparams):\n",
    "    models = {}\n",
    "\n",
    "    for name, checkpoint, tokenizer in architectures:\n",
    "        print(f\"Retraining {name} on full training set...\")\n",
    "\n",
    "        trds = Dataset.from_pandas(trdf)\n",
    "        valds = Dataset.from_pandas(tedf)\n",
    "\n",
    "        trds = trds.map(lambda batch: tokenize(tokenizer, batch), batched=True)\n",
    "        valds = valds.map(lambda batch: tokenize(tokenizer, batch), batched=True)\n",
    "\n",
    "        trds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_y\"])\n",
    "        valds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_y\"])\n",
    "\n",
    "        lr, bsz = best_hyperparams[name]\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'./final_results/{name}',\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=bsz,\n",
    "            per_device_eval_batch_size=bsz,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            logging_dir=f'./final_logs/{name}',\n",
    "            save_strategy=\"epoch\"\n",
    "        )\n",
    "\n",
    "        trainer = BalancedTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=trds,\n",
    "            eval_dataset=valds\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        models[name] = (model, tokenizer, metrics[\"eval_f1\"])\n",
    "    \n",
    "    # Calculate relative F1 scores for ensembling\n",
    "    tot_f1 = sum(m[2] for m in models.values())\n",
    "    for name in models:\n",
    "        model, tokenizer, f1 = models[name]\n",
    "\n",
    "        models[name] = (model, tokenizer, f1 / tot_f1)\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8dbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
